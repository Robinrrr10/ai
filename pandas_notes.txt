Pandas Notes:
------------

Tutorial used:
https://www.youtube.com/watch?v=tRKeLrwfUgU



--------------


Notes:
----
Pandas is used in data sceince and AI/Machine learning
It is used for handing datas

--------------

To install use below command
pip install pandas

-------------

Create / Read
-------

import pandas as pd       # this is for importing

df = pd.read_csv("myfile.csv")   # This will read csv file and save in df object

df             # To log df object

df.head()     # This will print first 5 rows
df.head(10)   # This will print first 10 rows
df.tail()     # This will print last 5 rows
df.tail(15)   # This will print last 15 rows

#There are many read funtions available for read, we can read from csv, sql, table, dictionary and many more

dictData = {"mykey1":[11, 42, 63], "mykey2":[78, 14, 89], "mykey3": [45, 23, 61]}          # this is for creating a dictionary in python

dictDf = pd.DataFrame.from_dict(dictData)          # This will read the dictionary



-------------


df.columns   # To show all available columns

df.dtypes       # To show datatypes of each columns

df.describe()    # To descible the data. It will show count, min, max, mean, std, 25%, 50%, 75%. This will show the int and fload types.

df.describe(include='object')   # This will describe object/string types. This will show count, no of uniques, top, freq


Print columns data
--------------

df.giveColumnNameHere    # This will give column
Eg: df.State    

df.giveColumnNameHere.unique()       #This will give unique values of the given column
Eg:df.State.unique()



df['givenColumnNameHere']        #This will give column
Eg:
df['International Plan']               #This will be helpful when column name has the space

df['givenColumnNameHere'].unique()   #this will give unique value of the given column
Eg:
df['International Plan'].unique()   

df['column1Name1', [columnName2]]       # We can get multiple column using this
Eg:
df['International Plan', 'State']     # THIs will give column name of Internation plan and state columns


Filters:
-------
df[df['columnName'] == value]      # This is to filter with required value of the columns

Eg:
df[df['International Plan'] == 'No']  #This will filter International plan matching with value No


df[(df['columnName1'] == value) & (df['columnName2'] == value)]    #This is the way we can give filters of multiple columns
Eg:
df[(df['International plan'] == 'No') & (df['Churn'] == True)]     # Here we are filtering with International plan matching with No and churn matching with True


--------

copy
---

To copy the data frame use below
newobj = df.copy()        #This is used to copy



-------------

iloc
--
This is used to filter with index (number)

df.iloc[givenIndexOfRow]      # This row with index and show in grid format
Eg:
df.iloc[4]                     # IT will show all content and values of 4th row


df.iloc[givenIndexOfRow, columNo]    # This will show the value. Here we are row and column number which is a cell
df.iloc[4, 3]                         # IT will give 4 row of 3 rd column valu


df.iloc[startIndex: lengthOrEndIndex]    #This is to show the range of rows
Eg:
df.iloc[10: 15]                          # THiswill rows from 10 to 15



------------

loc
---
This is used to filter with string
To use this we need to set the index for column using below

dfcp.set_index('giveColumnName', inplace=True)
Eg:
dfcp = df.copy()
dfcp.set_index('State', inplace=True)   

now if we view, it will show the index in dark

dfcp.loc('GiveValue')        # Shows matching rows
Eg:
dfcp.loc('OK')             # Shows matching data of this


-----------

df.isnull().summ()      # This will show number of nulls in each columns


Drop / Remove
---

df.dropna(inplace=True)   # This is to remove rows which has any column value as null

df.drop('columnName', axis=1)   # This is to remove the column
Eg:
df.drop('Area code', axis=1)   # This will remve the column Area code

--------

Creating column
------------
df['newColumnName'] = values   # This is used to create column with value

df['mycolumn'] =df['MyNew column'] = df['Total day calls'] + df['Total day charge']          # This will add these two columns and add in new column



Updating
------------

To give same value give below
df['mycolumn'] = 100   # This will update all column value as 100

df[rowIndex, columIndex] = valueToUpdate    # This is to update on specific cell (in given row in given column)
Eg:
df[2, 5] = 56                 # At two index 2, it updated on the column index 5

df[3, -1] = 'Hi'             # Negative is to give from reverse, here in 3rd index, it update on the last column with value Hi


--------

Apply
----
Adding other example of apply
https://www.geeksforgeeks.org/python/python-pandas-apply/

This apply will take the function as the argument and apply all values of the object and returns the series/


df['NewColumnName'] = df['ExistingColumn'].apply(lambda x updateValue1 if x==Valuecondition else updateValue2) # This will iterate in each and based on condition it will update it
Eg:
df['myNewColumn'] = df['Churn'].apply(lambda x 1 if x==True else 0)     # This will check whether any of the value in churn column matches with Tru or not, if matches it update 1 if not, it will update to 0
Eg:

----

Output
----
df.to_csv("giveFileName.csv")    # This will create a csv file with output or df on the current jupytor notebook directory

df.to_json()    # To give in json format

df.to_html()    # To give in html format

---

Delete
---

del df     # python code to delete the file




----

Median value
df.giveColumnName.median()

Eg:
df.price.median()                 # This will give the median value

------

Give replace null value

df.columnName.fillna(GiveValueToBeAddedHere)

Eg:
df.price.fillna(o.o)

--------------

To create new columns as per string values 
//To create dummies value

dummies = pd.get_dummies(df.columnName)

Eg:
dummies = pd.get_dummies(df.town)   //For each townname it will create columns. For matching it will set 1 and for not matching it will set 0


-------------

To concatinate two columns
-------

mergedtable = pd.concat([table1Name, table2Name],axis='columnsOrRows')

mergedtable = pd.concat([table1, table2],axis='columns') //This will merge columns of table 1 with table 2 and store in mergedtable



----------


To drop columns
---

newtable = table.drop(['headerName', 'headerName'], axis='columns or rows')  


mt = tb.drop(['town', 'chennai'], axis='columns')   # Here I have given two column header town and chennai to drop. Those are columns and I have to drop the columns. So have given axis='columns'


--------------------




















--------------
