Pandas Notes:
------------

Tutorial used:
https://www.youtube.com/watch?v=tRKeLrwfUgU



--------------


Notes:
----
Pandas is used in data sceince and AI/Machine learning
It is used for handing datas

--------------

To install use below command
pip install pandas

-------------

Create / Read
-------

import pandas as pd       # this is for importing

df = pd.read_csv("myfile.csv")   # This will read csv file and save in df object

df             # To log df object

df.head()     # This will print first 5 rows
df.head(10)   # This will print first 10 rows
df.tail()     # This will print last 5 rows
df.tail(15)   # This will print last 15 rows

#There are many read funtions available for read, we can read from csv, sql, table, dictionary and many more

dictData = {"mykey1":[11, 42, 63], "mykey2":[78, 14, 89], "mykey3": [45, 23, 61]}          # this is for creating a dictionary in python

dictDf = pd.DataFrame.from_dict(dictData)          # This will read the dictionary


We can also create data from from existing data frame and list of columns
df = pd.DataFrame(GiveDataFrameHere, columns=GiveDataFrameColumnNamesHere) //No of column nams should match with number of columns available in data frame 
Eg:
irisData = pd.DataFrame(iris.data, columns=iris.feature_names)   //Here iris.data has 4 columns with many rows of data. iris.feature_names has only 4 string as rown which will be assigned as the column for irisData) 

-------------


df.columns   # To show all available columns

df.dtypes       # To show datatypes of each columns

df.describe()    # To descible the data. It will show count, min, max, mean, std, 25%, 50%, 75%. This will show the int and fload types.

df.describe(include='object')   # This will describe object/string types. This will show count, no of uniques, top, freq


Print columns data
--------------

df.giveColumnNameHere    # This will give column
Eg: df.State    

df.giveColumnNameHere.unique()       #This will give unique values of the given column
Eg:df.State.unique()



df['givenColumnNameHere']        #This will give column
Eg:
df['International Plan']               #This will be helpful when column name has the space

df['givenColumnNameHere'].unique()   #this will give unique value of the given column
Eg:
df['International Plan'].unique()   

df['column1Name1', [columnName2]]       # We can get multiple column using this
Eg:
df['International Plan', 'State']     # THIs will give column name of Internation plan and state columns


Filters:
-------
df[df['columnName'] == value]      # This is to filter with required value of the columns

Eg:
df[df['International Plan'] == 'No']  #This will filter International plan matching with value No


df[(df['columnName1'] == value) & (df['columnName2'] == value)]    #This is the way we can give filters of multiple columns
Eg:
df[(df['International plan'] == 'No') & (df['Churn'] == True)]     # Here we are filtering with International plan matching with No and churn matching with True


--------

copy
---

To copy the data frame use below
newobj = df.copy()        #This is used to copy



-------------

iloc
--
This is used to filter with index (number)

df.iloc[givenIndexOfRow]      # This row with index and show in grid format
Eg:
df.iloc[4]                     # IT will show all content and values of 4th row


df.iloc[givenIndexOfRow, columNo]    # This will show the value. Here we are row and column number which is a cell
df.iloc[4, 3]                         # IT will give 4 row of 3 rd column valu


df.iloc[startIndex: lengthOrEndIndex]    #This is to show the range of rows
Eg:
df.iloc[10: 15]                          # THiswill rows from 10 to 15



------------

loc
---
This is used to filter with string
To use this we need to set the index for column using below

dfcp.set_index('giveColumnName', inplace=True)
Eg:
dfcp = df.copy()
dfcp.set_index('State', inplace=True)   

now if we view, it will show the index in dark

dfcp.loc('GiveValue')        # Shows matching rows
Eg:
dfcp.loc('OK')             # Shows matching data of this


-----------

df.isnull().summ()      # This will show number of nulls in each columns


Drop / Remove
---

df.dropna(inplace=True)   # This is to remove rows which has any column value as null

df.drop('columnName', axis=1)   # This is to remove the column
Eg:
df.drop('Area code', axis=1)   # This will remve the column Area code

--------

Creating column
------------
df['newColumnName'] = values   # This is used to create column with value

df['mycolumn'] =df['MyNew column'] = df['Total day calls'] + df['Total day charge']          # This will add these two columns and add in new column



Updating
------------

To give same value give below
df['mycolumn'] = 100   # This will update all column value as 100

df[rowIndex, columIndex] = valueToUpdate    # This is to update on specific cell (in given row in given column)
Eg:
df[2, 5] = 56                 # At two index 2, it updated on the column index 5

df[3, -1] = 'Hi'             # Negative is to give from reverse, here in 3rd index, it update on the last column with value Hi


--------

Apply
----
Adding other example of apply
https://www.geeksforgeeks.org/python/python-pandas-apply/

This apply will take the function as the argument and apply all values of the object and returns the series/


df['NewColumnName'] = df['ExistingColumn'].apply(lambda x updateValue1 if x==Valuecondition else updateValue2) # This will iterate in each and based on condition it will update it
Eg:
df['myNewColumn'] = df['Churn'].apply(lambda x 1 if x==True else 0)     # This will check whether any of the value in churn column matches with Tru or not, if matches it update 1 if not, it will update to 0
Eg:

----

Output
----
df.to_csv("giveFileName.csv")    # This will create a csv file with output or df on the current jupytor notebook directory

df.to_json()    # To give in json format

df.to_html()    # To give in html format

---

Delete
---

del df     # python code to delete the file




----

Median value
df.giveColumnName.median()

Eg:
df.price.median()                 # This will give the median value

------

Give replace null value

df.columnName.fillna(GiveValueToBeAddedHere)

Eg:
df.price.fillna(o.o)

--------------

To create new columns as per string values 
//To create dummies value

dummies = pd.get_dummies(df.columnName)

Eg:
dummies = pd.get_dummies(df.town)   //For each townname it will create columns. For matching it will set 1 and for not matching it will set 0


-------------

To concatinate two columns
-------

mergedtable = pd.concat([table1Name, table2Name],axis='columnsOrRows')

mergedtable = pd.concat([table1, table2],axis='columns') //This will merge columns of table 1 with table 2 and store in mergedtable



----------


To drop columns
---

newtable = table.drop(['headerName', 'headerName'], axis='columns or rows')  


mt = tb.drop(['town', 'chennai'], axis='columns')   # Here I have given two column header town and chennai to drop. Those are columns and I have to drop the columns. So have given axis='columns'


--------------------

shape
----
This will give number of rows and columns
df.shape

This will print number of rows and columns

------------------------



plot
----
This is used to plot the chart.
Pandas has this to show in the chart.
plot internally uses the matplotlib

df.plot()


df.plot(kind='bar')

df.plot(kind='line')

There are different kind of chart. We can pass chart type in the kind
In below document we can find the supporting charts kind

See below document for more details


------------------------------

crosstab
---------
This is used to take count of each values in first column based on second column

pd.crosstab(column1, column2)

Eg:
pd.crosstab(dep_emp_lef.Department, dep_emp_lef.emp_left)
This will give count of persons left in each department

Mostly helps when we wanted to deal with count of data based on column

--------------------------------------


round()
------
Used to round off the values

We can off the decimals by calling round() method

df.age[0].round()   //Round first value of age
df.age.mean().round()   //Get mean value of age and round off
df.age.round()    //Round all values of age

Eg:
input.Age = input.Age.fillna(input.Age.mean().round())

-------------------

gray() and matshow()
-------------------------

plt.gray()   // This is to set the color as gray
plt.matshow(digits.images[0])           //This is used to show the 2D array as the color coded matrix.For each value it shows the color etc

We can use these to combined and see the gray image of the 2D array values

--------------------

nunique()
---------

This will give number of unique values in each columns

df.nunique()

----------------

isna()
-----
This is to filter only data which has na or null or none value
df.isna()

---------

sum()     
---
This is to make the sum of the values or the count

df.isna().sum()

This will give sum of null or none values in each columns


---------

dropna()
--------

Below is to drop the rows which has null or none value

df.dropna(inplace=True)

This will remove all the rows which has null or none value


------------------

keys()
-----
This will show all available keys. Similar to dir

df.keys()


------------------------------

reshape()
---------
Used to reshape based on given 2 D array

digits.data[0].reshape(8, 8) //The 64 values of array will be recreated to 8 X 8 


-------------


values_count()
--------------
This will give number of values count in the column
df.columnName.values_count()
or
df['giveColumnName'].values_count()

Eg:
df.target.values_count()

This will give count of each values in the column target

Eg:
df['gender'].values_count()
This will give number of males, females, others count 


----------------------------------------












-----------------------



---------------------









--------------
